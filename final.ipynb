{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Курсовая работа. Мегафон.\n",
    "\n",
    "Необходимо построить алгоритм, который для каждой пары пользователь-услуга определит вероятность\n",
    "подключения услуги."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- id - идентификатор абонента\n",
    "- vas_id - подключаемая услуга\n",
    "- buy_time - время покупки, представлено в формате timestamp, для работы с этим столбцом понадобится функция datetime.fromtimestamp из модуля datetime\n",
    "- target - целевая переменная, где 1 означает подключение услуги, 0 - абонент не подключил услугу соответственно. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, KFold, cross_validate\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, MinMaxScaler\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion, make_pipeline\n",
    "from imblearn.pipeline import Pipeline as SM_Pipeline\n",
    "from imblearn.pipeline import make_pipeline as SM_make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix, make_scorer\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "RANDOM_STATE = 21"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "\n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balance_df_by_target(df, target_name, method='over'):\n",
    "    assert method in ['over', 'under', 'tomek', 'smote'], 'Неверный метод сэмплирования'\n",
    "    target_counts = df[target_name].value_counts()\n",
    "\n",
    "    major_class_name = target_counts.argmax()\n",
    "    minor_class_name = target_counts.argmin()\n",
    "\n",
    "    disbalance_coeff = int(target_counts[major_class_name] / target_counts[minor_class_name]) - 1\n",
    "    if method == 'over':\n",
    "        for i in range(disbalance_coeff):\n",
    "            sample = df[df[target_name] == minor_class_name].sample(target_counts[minor_class_name])\n",
    "            df = df.append(sample, ignore_index=True)\n",
    "            \n",
    "    elif method == 'under':\n",
    "        df_ = df.copy()\n",
    "        df = df_[df_[target_name] == minor_class_name]\n",
    "        tmp = df_[df_[target_name] == major_class_name]\n",
    "        df = df.append(tmp.iloc[\n",
    "            np.random.randint(0, tmp.shape[0], target_counts[minor_class_name])\n",
    "        ], ignore_index=True)\n",
    "\n",
    "    elif method == 'tomek':\n",
    "        from imblearn.under_sampling import TomekLinks\n",
    "        tl = TomekLinks()\n",
    "        X_tomek, y_tomek = tl.fit_sample(df.drop(columns=target_name), df[target_name])\n",
    "        df = pd.concat([X_tomek, y_tomek], axis=1)\n",
    "    \n",
    "    elif method == 'smote':\n",
    "        from imblearn.over_sampling import SMOTE\n",
    "        smote = SMOTE(sampling_strategy=0.4)\n",
    "        X_smote, y_smote = smote.fit_resample(df.drop(columns=target_name), df[target_name])\n",
    "        df = pd.concat([X_smote, y_smote], axis=1)\n",
    "\n",
    "    return df.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(X: pd.DataFrame):\n",
    "    assert isinstance(X, pd.DataFrame)\n",
    "    \n",
    "    X_nunique = X.apply(lambda x: x.nunique(dropna=False))\n",
    "\n",
    "    f_init = set(X_nunique.index.tolist())\n",
    "    f_const = set(X_nunique[X_nunique == 1].index.tolist())\n",
    "    f_numeric = (X.fillna(0).astype(int).sum() - X.fillna(0).sum()).abs()\n",
    "    f_numeric = set(f_numeric[f_numeric > 0].index.tolist())\n",
    "    f_other = f_init - (f_numeric | f_const)\n",
    "    f_binary = set(X.loc[:, f_other].columns[(\n",
    "        (X.loc[:, f_other].max() == 1) & \\\n",
    "        (X.loc[:, f_other].min() == 0) & \\\n",
    "        (X.loc[:, f_other].isnull().sum() == 0)\n",
    "    )])\n",
    "    f_other = f_other - f_binary\n",
    "    f_categorical = set(X_nunique.loc[f_other][X_nunique.loc[f_other] <= 10].index.tolist())\n",
    "    f_other = f_other - f_categorical\n",
    "    f_numeric = f_numeric | f_other\n",
    "    f_all = f_binary | f_categorical | f_numeric\n",
    "\n",
    "    print('f_init:', len(f_init))\n",
    "    print('f_const:', len(f_const))\n",
    "    print('f_binary:', len(f_binary))\n",
    "    print('f_categorical:', len(f_categorical))\n",
    "    print('f_numeric:', len(f_numeric))\n",
    "    \n",
    "    assert(len(f_init) == len(f_const) + len(f_binary) + len(f_numeric) + len(f_categorical))\n",
    "\n",
    "    return list(f_binary), list(f_categorical), list(f_numeric), list(f_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid_search(estimator, X, y, params_grid, cv, scoring='roc_auc'):\n",
    "    gsc = GridSearchCV(estimator, params_grid, scoring=scoring, cv=cv, n_jobs=-1)\n",
    "\n",
    "    gsc.fit(X, y)\n",
    "    print(\"Best %s score: %.2f\" % (scoring, gsc.best_score_))\n",
    "    print()\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(gsc.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "\n",
    "    for i, params in enumerate(gsc.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (gsc.cv_results_['mean_test_score'][i], gsc.cv_results_['std_test_score'][i] * 2, params))\n",
    "\n",
    "    print()\n",
    "    \n",
    "    return gsc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Загрузка данных и снижение занимаемой памяти."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vas_id</th>\n",
       "      <th>buy_time</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540968</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1537131600</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1454121</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1531688400</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2458816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1534107600</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3535012</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1535922000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1693214</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1535922000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  vas_id    buy_time  target\n",
       "0   540968     8.0  1537131600     0.0\n",
       "1  1454121     4.0  1531688400     0.0\n",
       "2  2458816     1.0  1534107600     0.0\n",
       "3  3535012     5.0  1535922000     0.0\n",
       "4  1693214     1.0  1535922000     0.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('data_train.csv', index_col='Unnamed: 0')\n",
    "df_train = reduce_mem_usage(df_train)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vas_id</th>\n",
       "      <th>buy_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3130519</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1548018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000860</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1548018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1099444</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1546808400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1343255</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1547413200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1277040</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1546808400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  vas_id    buy_time\n",
       "0  3130519     2.0  1548018000\n",
       "1  2000860     4.0  1548018000\n",
       "2  1099444     2.0  1546808400\n",
       "3  1343255     5.0  1547413200\n",
       "4  1277040     2.0  1546808400"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('data_test.csv', index_col='Unnamed: 0')\n",
    "df_test = reduce_mem_usage(df_test)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((831653, 4), (71231, 3))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_big = pd.read_csv('features.csv', chunksize=100000, iterator=True, sep='\\t')\n",
    "# df_big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_list = []\n",
    "# all_users = pd.concat([df_train, df_test]).id.unique()\n",
    "\n",
    "# for dfb in df_big:\n",
    "#     merge = dfb['id'].isin(all_users)\n",
    "#     dfb_filter = dfb[merge]\n",
    "#     df_list.append(dfb_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df_features = df_list[0]\n",
    "# for number in range(1, len(df_list)):\n",
    "#     df_features = pd.concat([df_features, df_list[number]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features.to_csv('short_features.csv')\n",
    "df_features = pd.read_csv('short_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features.drop(['Unnamed: 0', 'Unnamed: 0.1'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>buy_time</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>243</th>\n",
       "      <th>244</th>\n",
       "      <th>245</th>\n",
       "      <th>246</th>\n",
       "      <th>247</th>\n",
       "      <th>248</th>\n",
       "      <th>249</th>\n",
       "      <th>250</th>\n",
       "      <th>251</th>\n",
       "      <th>252</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2046132</td>\n",
       "      <td>1534712400</td>\n",
       "      <td>300.820029</td>\n",
       "      <td>1599.480888</td>\n",
       "      <td>286.879214</td>\n",
       "      <td>1585.013202</td>\n",
       "      <td>281.461754</td>\n",
       "      <td>1563.90821</td>\n",
       "      <td>-16.08618</td>\n",
       "      <td>654.013903</td>\n",
       "      <td>...</td>\n",
       "      <td>-977.373846</td>\n",
       "      <td>-613.770792</td>\n",
       "      <td>-25.996269</td>\n",
       "      <td>-35.630448</td>\n",
       "      <td>-295.747724</td>\n",
       "      <td>-17.832889</td>\n",
       "      <td>-0.694428</td>\n",
       "      <td>-4.175933</td>\n",
       "      <td>-0.45614</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2050810</td>\n",
       "      <td>1540760400</td>\n",
       "      <td>-86.209971</td>\n",
       "      <td>91.820888</td>\n",
       "      <td>-84.480786</td>\n",
       "      <td>110.333202</td>\n",
       "      <td>-89.898246</td>\n",
       "      <td>89.22821</td>\n",
       "      <td>-16.08618</td>\n",
       "      <td>-65.076097</td>\n",
       "      <td>...</td>\n",
       "      <td>-977.373846</td>\n",
       "      <td>-613.770792</td>\n",
       "      <td>-23.996269</td>\n",
       "      <td>190.369552</td>\n",
       "      <td>-286.747724</td>\n",
       "      <td>-25.832889</td>\n",
       "      <td>-0.694428</td>\n",
       "      <td>-12.175933</td>\n",
       "      <td>-0.45614</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2070757</td>\n",
       "      <td>1540760400</td>\n",
       "      <td>-96.799971</td>\n",
       "      <td>-408.179112</td>\n",
       "      <td>-110.740786</td>\n",
       "      <td>-460.786798</td>\n",
       "      <td>-114.038246</td>\n",
       "      <td>-479.77179</td>\n",
       "      <td>-16.08618</td>\n",
       "      <td>-65.076097</td>\n",
       "      <td>...</td>\n",
       "      <td>-925.373846</td>\n",
       "      <td>-561.770792</td>\n",
       "      <td>-21.996269</td>\n",
       "      <td>-37.630448</td>\n",
       "      <td>-151.747724</td>\n",
       "      <td>-24.832889</td>\n",
       "      <td>0.305572</td>\n",
       "      <td>-12.175933</td>\n",
       "      <td>-0.45614</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2071522</td>\n",
       "      <td>1544994000</td>\n",
       "      <td>-94.939971</td>\n",
       "      <td>-363.699112</td>\n",
       "      <td>-108.880786</td>\n",
       "      <td>-411.226798</td>\n",
       "      <td>-114.298246</td>\n",
       "      <td>-432.33179</td>\n",
       "      <td>-16.08618</td>\n",
       "      <td>-65.076097</td>\n",
       "      <td>...</td>\n",
       "      <td>-977.373846</td>\n",
       "      <td>-613.770792</td>\n",
       "      <td>-25.996269</td>\n",
       "      <td>-37.630448</td>\n",
       "      <td>-306.747724</td>\n",
       "      <td>-25.832889</td>\n",
       "      <td>-0.694428</td>\n",
       "      <td>-12.175933</td>\n",
       "      <td>-0.45614</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2075318</td>\n",
       "      <td>1533502800</td>\n",
       "      <td>-75.639971</td>\n",
       "      <td>669.690888</td>\n",
       "      <td>-89.580786</td>\n",
       "      <td>732.343202</td>\n",
       "      <td>-94.998246</td>\n",
       "      <td>736.65821</td>\n",
       "      <td>-16.08618</td>\n",
       "      <td>782.383903</td>\n",
       "      <td>...</td>\n",
       "      <td>-501.373846</td>\n",
       "      <td>-242.770792</td>\n",
       "      <td>-25.996269</td>\n",
       "      <td>-37.630448</td>\n",
       "      <td>-167.747724</td>\n",
       "      <td>-14.832889</td>\n",
       "      <td>2.305572</td>\n",
       "      <td>-4.175933</td>\n",
       "      <td>-0.45614</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902384</th>\n",
       "      <td>3513869</td>\n",
       "      <td>1548018000</td>\n",
       "      <td>82.370029</td>\n",
       "      <td>-123.429112</td>\n",
       "      <td>155.939214</td>\n",
       "      <td>-88.526798</td>\n",
       "      <td>150.521754</td>\n",
       "      <td>-109.63179</td>\n",
       "      <td>-16.08618</td>\n",
       "      <td>-65.076097</td>\n",
       "      <td>...</td>\n",
       "      <td>-928.373846</td>\n",
       "      <td>-570.770792</td>\n",
       "      <td>-23.996269</td>\n",
       "      <td>-37.630448</td>\n",
       "      <td>-271.747724</td>\n",
       "      <td>-22.832889</td>\n",
       "      <td>-0.694428</td>\n",
       "      <td>-12.175933</td>\n",
       "      <td>-0.45614</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902385</th>\n",
       "      <td>3516552</td>\n",
       "      <td>1547413200</td>\n",
       "      <td>-96.799971</td>\n",
       "      <td>-116.519112</td>\n",
       "      <td>-110.740786</td>\n",
       "      <td>-169.126798</td>\n",
       "      <td>-116.158246</td>\n",
       "      <td>-190.23179</td>\n",
       "      <td>-16.08618</td>\n",
       "      <td>226.583903</td>\n",
       "      <td>...</td>\n",
       "      <td>-975.373846</td>\n",
       "      <td>-613.770792</td>\n",
       "      <td>-25.996269</td>\n",
       "      <td>-37.630448</td>\n",
       "      <td>-5.747724</td>\n",
       "      <td>-24.832889</td>\n",
       "      <td>-0.694428</td>\n",
       "      <td>-12.175933</td>\n",
       "      <td>-0.45614</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902386</th>\n",
       "      <td>3517434</td>\n",
       "      <td>1548018000</td>\n",
       "      <td>-96.799971</td>\n",
       "      <td>-284.349112</td>\n",
       "      <td>-100.740786</td>\n",
       "      <td>-274.796798</td>\n",
       "      <td>-106.158246</td>\n",
       "      <td>-295.90179</td>\n",
       "      <td>-16.08618</td>\n",
       "      <td>-65.076097</td>\n",
       "      <td>...</td>\n",
       "      <td>-977.373846</td>\n",
       "      <td>-613.770792</td>\n",
       "      <td>-25.996269</td>\n",
       "      <td>-37.630448</td>\n",
       "      <td>-306.747724</td>\n",
       "      <td>-25.832889</td>\n",
       "      <td>-0.694428</td>\n",
       "      <td>-12.175933</td>\n",
       "      <td>-0.45614</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902387</th>\n",
       "      <td>3519714</td>\n",
       "      <td>1546808400</td>\n",
       "      <td>167.280029</td>\n",
       "      <td>110.140888</td>\n",
       "      <td>153.339214</td>\n",
       "      <td>57.533202</td>\n",
       "      <td>147.921754</td>\n",
       "      <td>36.42821</td>\n",
       "      <td>-2.00618</td>\n",
       "      <td>-50.996097</td>\n",
       "      <td>...</td>\n",
       "      <td>-977.373846</td>\n",
       "      <td>-613.770792</td>\n",
       "      <td>-14.996269</td>\n",
       "      <td>7.369552</td>\n",
       "      <td>-180.747724</td>\n",
       "      <td>-19.832889</td>\n",
       "      <td>0.305572</td>\n",
       "      <td>-12.175933</td>\n",
       "      <td>-0.45614</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>902388</th>\n",
       "      <td>3521152</td>\n",
       "      <td>1548018000</td>\n",
       "      <td>-96.799971</td>\n",
       "      <td>-198.259112</td>\n",
       "      <td>-110.740786</td>\n",
       "      <td>-250.866798</td>\n",
       "      <td>-116.158246</td>\n",
       "      <td>-263.72179</td>\n",
       "      <td>-16.08618</td>\n",
       "      <td>-65.076097</td>\n",
       "      <td>...</td>\n",
       "      <td>3312.626154</td>\n",
       "      <td>2447.229208</td>\n",
       "      <td>-22.996269</td>\n",
       "      <td>339.369552</td>\n",
       "      <td>17256.252276</td>\n",
       "      <td>-0.832889</td>\n",
       "      <td>0.305572</td>\n",
       "      <td>-12.175933</td>\n",
       "      <td>-0.45614</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>902389 rows × 255 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id    buy_time           0            1           2            3  \\\n",
       "0       2046132  1534712400  300.820029  1599.480888  286.879214  1585.013202   \n",
       "1       2050810  1540760400  -86.209971    91.820888  -84.480786   110.333202   \n",
       "2       2070757  1540760400  -96.799971  -408.179112 -110.740786  -460.786798   \n",
       "3       2071522  1544994000  -94.939971  -363.699112 -108.880786  -411.226798   \n",
       "4       2075318  1533502800  -75.639971   669.690888  -89.580786   732.343202   \n",
       "...         ...         ...         ...          ...         ...          ...   \n",
       "902384  3513869  1548018000   82.370029  -123.429112  155.939214   -88.526798   \n",
       "902385  3516552  1547413200  -96.799971  -116.519112 -110.740786  -169.126798   \n",
       "902386  3517434  1548018000  -96.799971  -284.349112 -100.740786  -274.796798   \n",
       "902387  3519714  1546808400  167.280029   110.140888  153.339214    57.533202   \n",
       "902388  3521152  1548018000  -96.799971  -198.259112 -110.740786  -250.866798   \n",
       "\n",
       "                 4           5         6           7  ...          243  \\\n",
       "0       281.461754  1563.90821 -16.08618  654.013903  ...  -977.373846   \n",
       "1       -89.898246    89.22821 -16.08618  -65.076097  ...  -977.373846   \n",
       "2      -114.038246  -479.77179 -16.08618  -65.076097  ...  -925.373846   \n",
       "3      -114.298246  -432.33179 -16.08618  -65.076097  ...  -977.373846   \n",
       "4       -94.998246   736.65821 -16.08618  782.383903  ...  -501.373846   \n",
       "...            ...         ...       ...         ...  ...          ...   \n",
       "902384  150.521754  -109.63179 -16.08618  -65.076097  ...  -928.373846   \n",
       "902385 -116.158246  -190.23179 -16.08618  226.583903  ...  -975.373846   \n",
       "902386 -106.158246  -295.90179 -16.08618  -65.076097  ...  -977.373846   \n",
       "902387  147.921754    36.42821  -2.00618  -50.996097  ...  -977.373846   \n",
       "902388 -116.158246  -263.72179 -16.08618  -65.076097  ...  3312.626154   \n",
       "\n",
       "                244        245         246           247        248       249  \\\n",
       "0       -613.770792 -25.996269  -35.630448   -295.747724 -17.832889 -0.694428   \n",
       "1       -613.770792 -23.996269  190.369552   -286.747724 -25.832889 -0.694428   \n",
       "2       -561.770792 -21.996269  -37.630448   -151.747724 -24.832889  0.305572   \n",
       "3       -613.770792 -25.996269  -37.630448   -306.747724 -25.832889 -0.694428   \n",
       "4       -242.770792 -25.996269  -37.630448   -167.747724 -14.832889  2.305572   \n",
       "...             ...        ...         ...           ...        ...       ...   \n",
       "902384  -570.770792 -23.996269  -37.630448   -271.747724 -22.832889 -0.694428   \n",
       "902385  -613.770792 -25.996269  -37.630448     -5.747724 -24.832889 -0.694428   \n",
       "902386  -613.770792 -25.996269  -37.630448   -306.747724 -25.832889 -0.694428   \n",
       "902387  -613.770792 -14.996269    7.369552   -180.747724 -19.832889  0.305572   \n",
       "902388  2447.229208 -22.996269  339.369552  17256.252276  -0.832889  0.305572   \n",
       "\n",
       "              250      251  252  \n",
       "0       -4.175933 -0.45614  0.0  \n",
       "1      -12.175933 -0.45614  0.0  \n",
       "2      -12.175933 -0.45614  1.0  \n",
       "3      -12.175933 -0.45614  0.0  \n",
       "4       -4.175933 -0.45614  0.0  \n",
       "...           ...      ...  ...  \n",
       "902384 -12.175933 -0.45614  0.0  \n",
       "902385 -12.175933 -0.45614  0.0  \n",
       "902386 -12.175933 -0.45614  0.0  \n",
       "902387 -12.175933 -0.45614  0.0  \n",
       "902388 -12.175933 -0.45614  0.0  \n",
       "\n",
       "[902389 rows x 255 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features = reduce_mem_usage(df_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Соединение датасетов, генерация фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['buy_time'] = df_train['buy_time'].apply(lambda x: datetime.fromtimestamp(x))\n",
    "df_test['buy_time'] = df_test['buy_time'].apply(lambda x: datetime.fromtimestamp(x))\n",
    "df_features['buy_time'] = df_features['buy_time'].apply(lambda x: datetime.fromtimestamp(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.sort_values(by='buy_time')\n",
    "df_test = df_test.sort_values(by='buy_time')\n",
    "df_features = df_features.sort_values(by='buy_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train.loc[df_train.id == 2101246]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_features.loc[df_features.id == 2101246]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# копируем признак - так как он затрется при merge_asof\n",
    "df_features['buy_time_copy'] = df_features['buy_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge_asof(df_train, df_features, on=\"buy_time\", by=\"id\", direction='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge_asof(df_test, df_features, on=\"buy_time\", by=\"id\", direction='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_features, df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим разницу в днях между предложением и покупкой (или непокупкой) как признак\n",
    "train['diff'] = (train['buy_time'] - train['buy_time_copy']).dt.days\n",
    "test['diff'] = (test['buy_time'] - test['buy_time_copy']).dt.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим день, месяц, год совершения покупки (или непокупки) как признак\n",
    "train['year'] = train['buy_time'].map(lambda x: x.year)\n",
    "train['month'] = train['buy_time'].map(lambda x: x.month)\n",
    "train['day'] = train['buy_time'].map(lambda x: x.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['year'] = test['buy_time'].map(lambda x: x.year)\n",
    "test['month'] = test['buy_time'].map(lambda x: x.month)\n",
    "test['day'] = test['buy_time'].map(lambda x: x.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим колонки в формате datetime\n",
    "train.drop(['buy_time_copy', 'buy_time'], axis=1, inplace=True)\n",
    "test.drop(['buy_time_copy', 'buy_time'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['vas_id'] = train['vas_id'].astype('int')\n",
    "test['vas_id'] = test['vas_id'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum().sum(), test.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохранение датасетов\n",
    "train.to_csv('train_processed.csv', index=False)\n",
    "test.to_csv('test_processed.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Оценка важности признков, baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train_processed.csv')\n",
    "test = pd.read_csv('test_processed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns='target')\n",
    "y = train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобьем датасет на тренировочную и валидационную выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, shuffle=True, test_size=0.3, stratify=y, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07801461778762914"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# посмотрим дисбаланс классов\n",
    "y_train.value_counts()[1] / y_train.value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07801590044936052"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()[1] / y_test.value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Делаем балансировку датасета по методу smote\n",
    "TARGET_NAME = 'target'\n",
    "train_balanced = balance_df_by_target(train, TARGET_NAME, method='smote')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_bal = train_balanced.drop(columns='target')\n",
    "y_bal = train_balanced['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bal, X_test_bal, y_train_bal, y_test_bal = train_test_split(X_bal, y_bal, shuffle=True, test_size=0.3, stratify=y_bal, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3999985185925889"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_bal.value_counts()[1] / y_train_bal.value_counts()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = pd.DataFrame(MinMaxScaler().fit_transform(X_train_bal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "required number of components for 80.0% of total VAR is 15\n",
      "required number of components for 90.0% of total VAR is 22\n",
      "required number of components for 95.0% of total VAR is 28\n",
      "required number of components for 97.5% of total VAR is 34\n",
      "required number of components for 99.0% of total VAR is 41\n",
      "required number of components for 99.9% of total VAR is 45\n"
     ]
    }
   ],
   "source": [
    "break_even = [0.8, 0.9, 0.95, 0.975, 0.99, 0.999]\n",
    "\n",
    "pca = PCA(n_components=45)\n",
    "X_train_pca = pca.fit_transform(X_train_pca)\n",
    "var_vector = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "for level in break_even:\n",
    "    temp_list = []\n",
    "    for n in var_vector:\n",
    "        if n<=level: temp_list.append(n)\n",
    "    print(f'required number of components for {level*100}% of total VAR is {len(temp_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f_init: 259\n",
      "f_const: 6\n",
      "f_binary: 0\n",
      "f_categorical: 2\n",
      "f_numeric: 251\n"
     ]
    }
   ],
   "source": [
    "f_binary, f_categorical, f_numeric, f_all = get_features(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        assert isinstance(X, pd.DataFrame)\n",
    "\n",
    "        try:\n",
    "            return X[self.columns]\n",
    "        except KeyError:\n",
    "            cols_error = list(set(self.columns) - set(X.columns))\n",
    "            raise KeyError(\"DataFrame does not contain the following columns: %s\" % cols_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Базовая модель - Логистическая Регрессия.\n",
    "- солвер SAGA, оптимизированный для больших датасетов\n",
    "- в качестве метода масштабирования - MinMaxScaler\n",
    "- метрика f1_score(macro)\n",
    "- балансировка классов SMOTE библиотеки imblearn (oversampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pipeline = SM_make_pipeline(\n",
    "    FeatureSelector(columns=f_all),\n",
    "    FeatureUnion(transformer_list=[\n",
    "        (\"numeric_features\", make_pipeline(\n",
    "            FeatureSelector(columns=f_numeric),\n",
    "            StandardScaler(),\n",
    "        )),\n",
    "        (\"categorical_features\", make_pipeline(\n",
    "            FeatureSelector(columns=f_categorical),\n",
    "            OneHotEncoder(handle_unknown='ignore')\n",
    "        ))\n",
    "    ]),\n",
    "    SMOTE(sampling_strategy=0.4, n_jobs=-1),\n",
    "    LogisticRegression(random_state=RANDOM_STATE, solver='liblinear'),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ... (step 1 of 4) Processing featureselector, total=   0.1s\n",
      "[Pipeline] ...... (step 2 of 4) Processing featureunion, total=   9.5s\n",
      "[Pipeline] ............. (step 3 of 4) Processing smote, total=11.5min\n",
      "[Pipeline]  (step 4 of 4) Processing logisticregression, total= 9.6min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('featureselector',\n",
       "                 FeatureSelector(columns=['25', '72', '100', '117', '196',\n",
       "                                          '195', 'diff', '215', '181', '227',\n",
       "                                          '59', '20', '46', '234', '14', '175',\n",
       "                                          '178', '53', '240', '74', '176',\n",
       "                                          '209', '110', '93', '131', '18', '61',\n",
       "                                          '242', '127', '96', ...])),\n",
       "                ('featureunion',\n",
       "                 FeatureUnion(transformer_list=[('numeric_features',\n",
       "                                                 Pipeline(steps=[('featureselector',\n",
       "                                                                  FeatureSelec...\n",
       "                                                                                           '96', ...])),\n",
       "                                                                 ('standardscaler',\n",
       "                                                                  StandardScaler())])),\n",
       "                                                ('categorical_features',\n",
       "                                                 Pipeline(steps=[('featureselector',\n",
       "                                                                  FeatureSelector(columns=['vas_id',\n",
       "                                                                                           'month'])),\n",
       "                                                                 ('onehotencoder',\n",
       "                                                                  OneHotEncoder(handle_unknown='ignore'))]))])),\n",
       "                ('smote', SMOTE(n_jobs=-1, sampling_strategy=0.4)),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(random_state=21, solver='liblinear'))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.91      0.94    231440\n",
      "         1.0       0.38      0.70      0.49     18056\n",
      "\n",
      "    accuracy                           0.90    249496\n",
      "   macro avg       0.68      0.80      0.72    249496\n",
      "weighted avg       0.93      0.90      0.91    249496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict = base_pipeline.predict(X_test)\n",
    "print(classification_report(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Обучение других моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если добавляю снижение размерности - то вместе со временем просчета модели очень резко снижается macro avg."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lr_svd_l2 = SM_make_pipeline(\n",
    "    FeatureSelector(columns=f_all),\n",
    "    FeatureUnion(transformer_list=[\n",
    "        (\"numeric_features\", make_pipeline(\n",
    "            FeatureSelector(columns=f_numeric),\n",
    "            StandardScaler(),\n",
    "        )),\n",
    "        (\"categorical_features\", make_pipeline(\n",
    "            FeatureSelector(columns=f_categorical),\n",
    "            OneHotEncoder(handle_unknown='ignore')\n",
    "        ))\n",
    "    ]),\n",
    "    TruncatedSVD(n_components=45),\n",
    "    SMOTE(sampling_strategy=0.4, n_jobs=-1),\n",
    "    LogisticRegression(penalty='l2', solver='saga', random_state=RANDOM_STATE, \n",
    "                                  class_weight='balanced', n_jobs=-1),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ... (step 1 of 5) Processing featureselector, total=   0.1s\n",
      "[Pipeline] ...... (step 2 of 5) Processing featureunion, total=   9.5s\n",
      "[Pipeline] ...... (step 3 of 5) Processing truncatedsvd, total=  37.9s\n",
      "[Pipeline] ............. (step 4 of 5) Processing smote, total=  25.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gribanov\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline]  (step 5 of 5) Processing logisticregression, total=  48.5s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.54      0.68    231440\n",
      "         1.0       0.08      0.53      0.14     18056\n",
      "\n",
      "    accuracy                           0.54    249496\n",
      "   macro avg       0.51      0.53      0.41    249496\n",
      "weighted avg       0.87      0.54      0.64    249496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_lr_svd_l2.fit(X_train, y_train)\n",
    "predict_pca = pipe_lr_svd_l2.predict(X_test)\n",
    "print(classification_report(y_test, predict_pca))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "GB_pipeline = make_pipeline(\n",
    "    FeatureSelector(columns=f_all),\n",
    "    FeatureUnion(transformer_list=[\n",
    "        (\"numeric_features\", make_pipeline(\n",
    "            FeatureSelector(columns=f_numeric),\n",
    "            StandardScaler()\n",
    "        )),\n",
    "        (\"categorical_features\", make_pipeline(\n",
    "            FeatureSelector(columns=f_categorical),\n",
    "            OneHotEncoder(handle_unknown='ignore')\n",
    "        ))\n",
    "    ]),\n",
    "    GradientBoostingClassifier(random_state=RANDOM_STATE),\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n",
      "[Pipeline] ... (step 1 of 3) Processing featureselector, total=   0.1s\n",
      "[Pipeline] ...... (step 2 of 3) Processing featureunion, total=   9.5s\n",
      "[Pipeline]  (step 3 of 3) Processing gradientboostingclassifier, total=20.2min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('featureselector',\n",
       "                 FeatureSelector(columns=['25', '72', '100', '117', '196',\n",
       "                                          '195', 'diff', '215', '181', '227',\n",
       "                                          '59', '20', '46', '234', '14', '175',\n",
       "                                          '178', '53', '240', '74', '176',\n",
       "                                          '209', '110', '93', '131', '18', '61',\n",
       "                                          '242', '127', '96', ...])),\n",
       "                ('featureunion',\n",
       "                 FeatureUnion(transformer_list=[('numeric_features',\n",
       "                                                 Pipeline(steps=[('featureselector',\n",
       "                                                                  FeatureSelec...\n",
       "                                                                                           '209',\n",
       "                                                                                           '110',\n",
       "                                                                                           '93',\n",
       "                                                                                           '131',\n",
       "                                                                                           '18',\n",
       "                                                                                           '61',\n",
       "                                                                                           '242',\n",
       "                                                                                           '127',\n",
       "                                                                                           '96', ...])),\n",
       "                                                                 ('standardscaler',\n",
       "                                                                  StandardScaler())])),\n",
       "                                                ('categorical_features',\n",
       "                                                 Pipeline(steps=[('featureselector',\n",
       "                                                                  FeatureSelector(columns=['vas_id',\n",
       "                                                                                           'month'])),\n",
       "                                                                 ('onehotencoder',\n",
       "                                                                  OneHotEncoder(handle_unknown='ignore'))]))])),\n",
       "                ('gradientboostingclassifier',\n",
       "                 GradientBoostingClassifier(random_state=21))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time\n",
    "GB_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.99      0.97    231440\n",
      "         1.0       0.69      0.25      0.37     18056\n",
      "\n",
      "    accuracy                           0.94    249496\n",
      "   macro avg       0.82      0.62      0.67    249496\n",
      "weighted avg       0.93      0.94      0.92    249496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict = GB_pipeline.predict(X_test)\n",
    "print(classification_report(y_test, predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Pool(data=X_train,\n",
    "                   label=y_train)\n",
    "\n",
    "eval_dataset = Pool(X_test,\n",
    "                     label=y_test)\n",
    "\n",
    "cb_model = CatBoostClassifier(iterations=2500,\n",
    "                           depth=10,\n",
    "                           learning_rate=0.1,\n",
    "                           loss_function='Logloss',\n",
    "                           eval_metric='AUC',\n",
    "                           early_stopping_rounds=50,\n",
    "                           grow_policy='Depthwise',\n",
    "                           random_state=42,\n",
    "                           thread_count=4,\n",
    "                           use_best_model=True,\n",
    "                           verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1a1e77552e0>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb_model.fit(train_data, eval_set=eval_dataset, logging_level='Silent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.99      0.97    231440\n",
      "         1.0       0.66      0.28      0.40     18056\n",
      "\n",
      "    accuracy                           0.94    249496\n",
      "   macro avg       0.80      0.64      0.68    249496\n",
      "weighted avg       0.93      0.94      0.93    249496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_class = cb_model.predict(X_test)\n",
    "print(classification_report(y_test, preds_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Проведем подбор параметров для CatBoost, используем кросс-валидцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_cv = KFold(n_splits=3, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_catb = CatBoostClassifier(cat_features=['id', 'vas_id'],\n",
    "                                      silent=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    \"learning_rate\": [0.1],\n",
    "    \"depth\": [3],\n",
    "    \"iterations\": [300],\n",
    "    'l2_leaf_reg': [5, 15, 25]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "# catb_gsc = run_grid_search(model_catb, X_train, y_train, param_grid, kfold_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_catb = CatBoostClassifier(n_estimators=200,\n",
    "                                 max_depth=3, \n",
    "                                 l2_leaf_reg=15,\n",
    "                                 learning_rate=0.1,\n",
    "                                 cat_features=['id', 'vas_id'], \n",
    "                                 silent=True, \n",
    "                                 random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1a1e7010520>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model_catb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 262 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "catb_pred = model_catb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      1.00      0.97    231440\n",
      "         1.0       0.92      0.32      0.48     18056\n",
      "\n",
      "    accuracy                           0.95    249496\n",
      "   macro avg       0.93      0.66      0.73    249496\n",
      "weighted avg       0.95      0.95      0.94    249496\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, catb_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Сохранение финальной модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pickle', 'wb') as f:\n",
    "    pickle.dump(model_catb, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Предсказание на test выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model.pickle', 'rb') as f:\n",
    "    model_catb =  pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подготовленный тестовый датасет взят из пункта 2\n",
    "test_preds = model_catb.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vas_id</th>\n",
       "      <th>buy_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3130519</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1548018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000860</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1548018000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1099444</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1546808400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1343255</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1547413200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1277040</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1546808400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  vas_id    buy_time\n",
       "0  3130519     2.0  1548018000\n",
       "1  2000860     4.0  1548018000\n",
       "2  1099444     2.0  1546808400\n",
       "3  1343255     5.0  1547413200\n",
       "4  1277040     2.0  1546808400"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = pd.read_csv('data_test.csv', index_col='Unnamed: 0')\n",
    "df_test = reduce_mem_usage(df_test)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>vas_id</th>\n",
       "      <th>buy_time</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3130519</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1548018000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2000860</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1548018000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1099444</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1546808400</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1343255</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1547413200</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1277040</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1546808400</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  vas_id    buy_time  target\n",
       "0  3130519     2.0  1548018000     0.0\n",
       "1  2000860     4.0  1548018000     0.0\n",
       "2  1099444     2.0  1546808400     1.0\n",
       "3  1343255     5.0  1547413200     0.0\n",
       "4  1277040     2.0  1546808400     0.0"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['target'] = test_preds\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.to_csv('answers_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
